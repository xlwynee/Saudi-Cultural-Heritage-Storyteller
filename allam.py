# -*- coding: utf-8 -*-
"""ÙAllam2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q9WUmyL6sYwu14gBCqxKyteW1FLsi3y9
"""

!pip install gradio duckduckgo-search transformers accelerate sentencepiece bitsandbytes --quiet

!pip install duckduckgo_search --upgrade --quiet

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from duckduckgo_search import DDGS

model_name = 'ALLAM-AI/ALLaM-7B-Instruct-preview'

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', trust_remote_code=True)

story_generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

import pandas as pd
df = pd.read_csv('datasetAdvanced.csv')
df.head()

def get_site_and_generate_story(user_input, user_age):
    match = df[df['Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹'].str.contains(user_input, case=False, na=False)]

    if match.empty:
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ Ù…Ø·Ø§Ø¨Ù‚."

    site = match.iloc[0]
    site_name = site['Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹']
    description = site['Ø§Ù„ÙˆØµÙ']
    region = site['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©']
    source = site['Ø§Ù„Ù…ØµØ¯Ø±']

    if user_age == "Ø£Ø·ÙØ§Ù„":
        tone = "Ø§ÙƒØªØ¨ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ ..."
    elif user_age == "Ù…Ø±Ø§Ù‡Ù‚ÙŠÙ†":
        tone = "Ø§ÙƒØªØ¨ Ù‚ØµØ© Ù‚ØµÙŠØ±Ø© Ø¨Ù„ØºØ© Ù…Ø´ÙˆÙ‚Ø© ..."
    else:
        tone = "Ø§ÙƒØªØ¨ Ù‚ØµØ© ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø£Ø¯Ø¨ÙŠ ..."

    prompt = f"""
{tone}
Ø§Ù„Ù…ÙˆÙ‚Ø¹: "{site_name}" - Ù…Ù†Ø·Ù‚Ø© {region}
Ø§Ù„ÙˆØµÙ: {description}
Ø§Ù„Ù…ØµØ¯Ø±: {source}
ÙŠØ±Ø¬Ù‰ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù‚ØµØ© Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©ØŒ ÙˆØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© ({user_age}).
Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù‚ØµØ© Ø§Ù„Ø¢Ù†:
"""

    result = story_generator(
        prompt,
        max_length=150,
        temperature=0.7,
        top_p=0.95,
        repetition_penalty=1.1,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,
        eos_token_id=tokenizer.eos_token_id
    )

    full_text = result[0]["generated_text"]
    story_only = full_text.replace(prompt, "").strip()

    print("âœ… Ø§Ù„Ù‚ØµØ©:", story_only)

    return story_only

import gradio as gr

interface = gr.Interface(
    fn=get_site_and_generate_story,
    inputs=[
        gr.Textbox(label="ğŸ•Œ Ø£Ø¯Ø®Ù„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªØ±Ø§Ø«ÙŠ:"),
        gr.Dropdown(choices=["Ø£Ø·ÙØ§Ù„", "Ù…Ø±Ø§Ù‡Ù‚ÙŠÙ†", "Ø¨Ø§Ù„ØºÙŠÙ†"], label="ğŸ‘¥ Ø§Ø®ØªØ± Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©", value=None)
    ],
    outputs=[
        gr.Textbox(label="ğŸ“œ Ø§Ù„Ù‚ØµØ©", lines=15, max_lines=30, interactive=False)
        #gr.Image(label="ğŸ–¼ï¸ ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹")
    ],
    title="ğŸ“– Ø§Ø³ØªÙƒØ´Ù Ø§Ù„ØªØ±Ø§Ø« Ø§Ù„Ø«Ù‚Ø§ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ",
    description="Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ù…ÙˆÙ‚Ø¹ ØªØ±Ø§Ø«ÙŠ ÙˆØ§Ø®ØªØ± Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©ØŒ ÙˆØ³Ù†Ø­ÙƒÙŠ Ù„Ùƒ Ù‚ØµØ© Ù…Ø´ÙˆÙ‘Ù‚Ø© ÙˆÙ†Ø±ÙŠÙƒ ØµÙˆØ±Ø© Ù„Ù„Ù…ÙˆÙ‚Ø¹!"
)

interface.launch()